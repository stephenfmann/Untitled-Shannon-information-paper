\section{Ubquitous information}\label{sec:ubiquitous}

\subsection{How scientists use information theory}\label{subsec:scientists}

The tools of information theory are statistical tools.
Chief among them is mutual information, typically interpreted as a measure of the strength of correlation between two variables.
Mutual information has been employed by a diverse range of scientists, including:

\begin{itemize}
    \item Behavioural ecologists, to measure the correlation between the honey bee waggle dance and the location of food sources \citep{haldane1954statistical}
    \item Molecular biologists, to measure the correlation between inputs and outputs of a quorum-sensing bacterium \citep{mehta2009information}
    \item Evolutionary biologists, to measure the growth rate of an organism conditioning its behaviour on an environmental cue \citep{donaldson-matasci2010fitness}
    \item Cosmologists, to measure the correlation between galaxies' internal morphology and their local environments \citep{pandey2017how}
    \item Linguists, to measure the co-occurrence of words in a corpus \citep[$\S$4]{hunston2002corpora}
    \item Neuroscientists, to measure the correlation between neural firings and environmental states \citep[][and references therein]{rathkopf2017neural}
\end{itemize}

\noindent That many things correlate in the natural world is a useful fact for science to exploit.
Correlations increase the opportunity to discover features about a target phenomenon.
If the target is difficult to observe, it can nonetheless be studied via observing something that correlates with it. 

Correlations play a further role in the functional sciences.
Biological and cognitive agents can themselves make use of correlations.
The scientist is therefore interested in how correlations are exploited by agents other than scientists themselves.

Mutual information quantifies the strength of a correlation no matter who or what is exploiting that correlation.
The measure is maximally broad: its application is not limited to the functional sciences.

That a vehicle has positive mutual information with something it correlates with cannot determine whether that vehicle is an environmental cue or a signal.

%%%%%%
%%%%%%
%%%%%%
%%%%%%
\subsection{The argument for insufficiency of information theory}

The argument is as follows: because mutual information cannot distinguish signals and cues, information theory cannot distinguish signals and cues.

The argument requires a premise to the effect that the only tools available to information theory are mutual information and related measures.
In effect, the sceptic claims that all of the tools of information theory are insufficient to distinguish signals and cues.


%%%%%%
%%%%%%
%%%%%%
%%%%%%
\subsection{Communication theory distinguishes signals and cues}

I wish to argue that it is irrelevant whether or not information theory has the tools to distinguish signals and cues.
The theory whose application to naturalistic intentionality should be of interest to philosophers is communication theory.
Whereas information theory is a collection of mathematical tools with wide application across the sciences, communication theory is an engineering discipline with the specific goal of designing efficient signalling techniques.